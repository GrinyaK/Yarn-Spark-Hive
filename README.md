# Yarn-Spark-Hive
# YARN  
YARN (Yet Another Resource Negotiator) — это компонент из экосистемы Hadoop, отвечающий за управление ресурсами в кластерной архитектуре и запускает задания (например, MapReduce, Spark или другие фреймворки).

- Главная роль:
  - Управляет распределением ресурсов (CPU, память) между различными приложениями в кластере Hadoop.
  - Поддерживает выполнение задач на нескольких узлах кластера одновременно.
  
- Как работает:
  - Resource Manager: Центральный компонент, который управляет доступными ресурсами кластера.
  - Node Managers: Контролируют ресурсы отдельных узлов.
  - Работает с различными фреймворками (например, MapReduce или Spark).
  
- Пригоден для:  
  - Распределенных вычислений и обеспечения эффективного использования ресурсов.

Основные процессы YARN:
1. ResourceManager (RM): Управляет всеми ресурсами кластера, занимается распределением памяти и процессорного времени.
2. NodeManager (NM): Работает на каждом узле кластера, отвечает за управление ресурсами данного узла, например, запуск контейнеров.
3. ApplicationMaster (AM): Управляет выполнением конкретного приложения (например, MapReduce или Spark job). Один AM создается для каждого запущенного приложения.
4. Container: Основная единица, которая выделяется YARN для выполнения задач (например, мапперы, редьюсеры, Spark executors).

Ключевые конфигурационные файлы YARN:
- yarn-site.xml: Основной файл конфигурации YARN.

  -      <property>
         <name>yarn.resourcemanager.address</name>
         <value>resourcemanager_hostname:8032</value>
         <description>Адрес ResourceManager host</description>
         </property>
         <property>
         <name>yarn.nodemanager.resource.memory-mb</name>
         <value>16384</value>
         <description>Максимальный объем памяти RAM для контейнеров на одном узле</description>
         </property>
         <property>
         <name>yarn.scheduler.maximum-allocation-mb</name>
         <value>8192</value>
         <description>Максимальная память для одного контейнера</description>
         </property>
     

Процесс выполнения Jobs на YARN:
1. Клиент отправляет задание на ResourceManager.
2. ResourceManager выделяет контейнер для запуска ApplicationMaster.
3. ApplicationMaster организует выполнение задачи на узлах.
4. NodeManager запускает контейнеры для выполнения конкретной задачи (e.g., MapReduce Task, Spark Executor).
5. Когда задача завершена, ApplicationMaster возвращает статус в ResourceManager и освобождает ресурсы.

# Hive  
Hive — это хранилище данных (Data Warehouse) поверх Hadoop, которое позволяет писать SQL-запросы к данным в HDFS.  

- Главная роль:  
  - Позволяет аналитикам и разработчикам использовать SQL-подобный язык (HiveQL) для работы с большими данными без необходимости писать код MapReduce.
  
- Ключевые особенности:
  - Поддерживает обработку структурированных данных, хранящихся в HDFS.
  - Включает функции создания таблиц, работы с данными, их анализа и агрегации.
  - Может быть интегрирован со сторонними инструментами BI.
- Пригоден для:  
  - Запросов к огромным объемам данных с использованием SQL.
Как говорилось ранее Hive позволяет писать SQL-подобные запросы для работы с данными в HDFS (Hadoop Distributed File System). Это проще, чем писать MapReduce вручную. Вот пример запроса в Hive :


# Spark  
Apache Spark — это фреймворк для высокопроизводительных параллельных вычислений, предназначенный для обработки больших данных.

- Главная роль:  
  - Заботится об ускорении обработки данных за счет вычислений в памяти, минимизируя операции с дисками (в сравнении с MapReduce).

- Ключевые особенности:
  - Унифицированная обработка данных: ETL, потоковые данные, машинное обучение, SQL-запросы.
  - Работает быстрее традиционных Hadoop MapReduce.
  - Поддерживает работу как с HDFS, так и с другими источниками данных.
  
- Компоненты Spark:
  - Spark SQL: Для работы с данными через SQL.
  - Spark Streaming: Для обработки потоковых данных в реальном времени.
  - MLlib: Для задач машинного обучения.
  - GraphX: Для графовых вычислений.
- Пригоден для:  
  - Высокоскоростной обработки, потоковой обработки, многосложного анализа в распределенных системах (кластерах).
